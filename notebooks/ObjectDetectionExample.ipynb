{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rf_raster_vision_plugin.evaluate.config import VisionObjectDetectionEvaluatorConfigBuilder\n",
    "from rf_raster_vision_plugin.raster_source.config import RfRasterSourceConfigBuilder\n",
    "from rf_raster_vision_plugin.label_source.config import RfLabelSourceConfigBuilder\n",
    "from rf_raster_vision_plugin.label_store.config import RfLabelStoreConfigBuilder\n",
    "import rf_raster_vision_plugin.http.raster_foundry as rf\n",
    "from rf_raster_vision_plugin.http import vision\n",
    "import rastervision as rv\n",
    "from rastervision.task.task_config import TaskConfig\n",
    "from matplotlib import RcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "from rastervision.core import Box\n",
    "from rastervision.data.dataset_config import DatasetConfig\n",
    "from rastervision.data.scene_config import SceneConfig\n",
    "from rastervision.experiment.experiment_config import ExperimentConfig\n",
    "from rastervision.rv_config import RVConfig\n",
    "from uuid import uuid4\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup objects in vision API\n",
    "\n",
    "We'll need:\n",
    "\n",
    "- a project\n",
    "- an experiment\n",
    "\n",
    "We're ignoring scenes for now, since there\n",
    "[isn't an obvious way](https://github.com/azavea/raster-vision/blob/master/rastervision/evaluation/classification_evaluator.py#L23-L43)\n",
    "to hook into per-scene evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_project_id = '71820687-526e-4203-8aab-3bf1acd5cc70' # a public project\n",
    "rf_project_layer_id = '3cec2bbe-bb42-4df8-9478-bc8e57ab011e' # that project's default layer\n",
    "rf_host = 'app.staging.rasterfoundry.com'\n",
    "refresh_token = '9f8wgc5x2LH8o4j2LiB_MvxE-Yp4LmjwqaL35Vi9uDlYH'\n",
    "\n",
    "vision_host = 'prediction.staging.rasterfoundry.com'\n",
    "\n",
    "token = 'Bearer ' + rf.get_api_token(refresh_token, rf_host)\n",
    "vision_project = vision.create_project(token, vision_host, 'object detection example')\n",
    "vision_experiment = vision.create_experiment(\n",
    "    token,\n",
    "    vision_host,\n",
    "    'object detection example',\n",
    "    vision_project['id'],\n",
    "    'super advanced ml model',\n",
    "    'complicated and good',\n",
    "    'object detection'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-21 20:13:16:rastervision.utils.files: INFO - Downloading s3://raster-prediction-api-dev-andrew/clipped-cog-damage.tif to /tmp/tmpurjomyqn/s3/raster-prediction-api-dev-andrew/clipped-cog-damage.tif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('LABEL_SOURCE', 'RF_ANNOTATION_GROUP_LABEL_SOURCE'): <class 'rf_raster_vision_plugin.label_source.config.RfLabelSourceConfigBuilder'>, ('RASTER_SOURCE', 'RF_LAYER_RASTER_SOURCE'): <class 'rf_raster_vision_plugin.raster_source.config.RfRasterSourceConfigBuilder'>, ('LABEL_STORE', 'RF_ANNOTATION_GROUP_LABEL_STORE'): <class 'rf_raster_vision_plugin.label_store.config.RfLabelStoreConfigBuilder'>, ('EVALUATOR', 'RF_RV_OBJECT_DETECTION_EVALUATOR'): <class 'rf_raster_vision_plugin.evaluate.config.VisionObjectDetectionEvaluatorConfigBuilder'>}\n"
     ]
    }
   ],
   "source": [
    "rs_config = RfRasterSourceConfigBuilder() \\\n",
    "    .with_project_id(rf_project_id) \\\n",
    "    .with_project_layer_id(rf_project_layer_id) \\\n",
    "    .with_refresh_token(refresh_token) \\\n",
    "    .with_channel_order([1, 2, 3]) \\\n",
    "    .with_num_channels(3) \\\n",
    "    .build()\n",
    "raster_source = rs_config.create_source('/tmp')\n",
    "\n",
    "label_source_config = RfLabelSourceConfigBuilder() \\\n",
    "    .with_annotation_group('59388cf6-5105-467c-a8f3-f098055be8f0') \\\n",
    "    .with_project_id(rf_project_id) \\\n",
    "    .with_project_layer_id(rf_project_layer_id) \\\n",
    "    .with_refresh_token(refresh_token) \\\n",
    "    .with_crs_transformer(raster_source.get_crs_transformer()) \\\n",
    "    .build()\n",
    "label_source = label_source_config.create_source()\n",
    "\n",
    "label_store_config = RfLabelStoreConfigBuilder() \\\n",
    "    .with_annotation_group('59388cf6-5105-467c-a8f3-f098055be8f0') \\\n",
    "    .with_project_id(rf_project_id) \\\n",
    "    .with_project_layer_id(rf_project_layer_id) \\\n",
    "    .with_refresh_token(refresh_token) \\\n",
    "    .with_crs_transformer(raster_source.get_crs_transformer()) \\\n",
    "    .with_class_map({v: k for k, v in label_source._class_map.items()}) \\\n",
    "    .build()\n",
    "\n",
    "\n",
    "\n",
    "# then use the scene_config to make a dataset\n",
    "task_config = TaskConfig.builder(rv.OBJECT_DETECTION) \\\n",
    "    .with_chip_size(200) \\\n",
    "    .with_classes({\n",
    "        '870e82d4-0063-44f4-8a14-950266b23619': (1, 'red')\n",
    "    }).build()\n",
    "\n",
    "# use all the above to make a scene_config\n",
    "scene_config = SceneConfig.builder() \\\n",
    "    .with_task(task_config) \\\n",
    "    .with_raster_source(rs_config) \\\n",
    "    .with_label_source(label_source_config) \\\n",
    "    .with_label_store(label_store_config) \\\n",
    "    .with_id('example scene') \\\n",
    "    .build()\n",
    "\n",
    "# dataset config\n",
    "\n",
    "dataset_config = DatasetConfig.builder() \\\n",
    "    .with_train_scenes([scene_config]) \\\n",
    "    .with_validation_scenes([scene_config]) \\\n",
    "    .with_test_scenes([scene_config]) \\\n",
    "    .build()\n",
    "\n",
    "# then create an evaluator\n",
    "evaluator = VisionObjectDetectionEvaluatorConfigBuilder() \\\n",
    "    .with_project_id(vision_project['id']) \\\n",
    "    .with_experiment_id(vision_experiment['id']) \\\n",
    "    .with_refresh_token(refresh_token) \\\n",
    "    .with_class_map(label_source._class_map) \\\n",
    "    .with_output_uri('/tmp') \\\n",
    "    .build()\n",
    "\n",
    "\n",
    "backend_config = rv.BackendConfig.builder(rv.TF_OBJECT_DETECTION) \\\n",
    "    .with_task(task_config) \\\n",
    "    .with_debug(True) \\\n",
    "    .with_batch_size(16) \\\n",
    "    .with_num_steps(100000) \\\n",
    "    .with_model_defaults(rv.SSD_MOBILENET_V1_COCO) \\\n",
    "    .build()\n",
    "\n",
    "# then create an experiment config that uses the evaluator and the task and the dataset\n",
    "experiment_config = ExperimentConfig.builder() \\\n",
    "    .with_id('testexperiment') \\\n",
    "    .with_root_uri('/tmp') \\\n",
    "    .with_task(task_config) \\\n",
    "    .with_backend(backend_config) \\\n",
    "    .with_dataset(dataset_config) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = experiment_config.fully_resolve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
